{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Assignment 2: Emotion Classification"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28610c7646adf47e"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/ygao/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "#all dependencies\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T13:02:46.482921Z",
     "start_time": "2024-02-22T13:02:45.971728Z"
    }
   },
   "id": "e096f749c73a9e61"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "#constants\n",
    "DATA_LOCATION = '../data/go_emotions_dataset.csv'\n",
    "CLEAN_DATA_LOCATION = '../data/'\n",
    "MODEL_LOCATION = '../model/'\n",
    "RANDOM_SEED = 297"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T17:27:41.991653Z",
     "start_time": "2024-02-21T17:27:41.984340Z"
    }
   },
   "id": "e3d6ab30afd54603"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data preparation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ebd70144a21131e1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We load the data from local source, and split it into train validation and test sets. \n",
    "Split corpus and target."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2f78ca7b35e6570"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "#load dataset\n",
    "def load_data(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    df_raw_data = df.drop(columns=['id', 'example_very_unclear']) #text+categories\n",
    "    category_columns = df_raw_data.columns[1:28] #extract categories\n",
    "    df_data = pd.DataFrame({ #creating new df with 'text' and 'target\n",
    "        'text': df_raw_data['text'],\n",
    "        'target': df_raw_data[category_columns].apply(lambda row: row.values.tolist(), axis=1)\n",
    "    })\n",
    "    return df_data\n",
    "\n",
    "df = load_data(DATA_LOCATION)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T17:13:51.503706Z",
     "start_time": "2024-02-21T17:13:50.741939Z"
    }
   },
   "id": "5d183f80276fce22"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "#split dataset into train, validation, test (70% 15% 15%)\n",
    "#train: 147857 validation/test: 31684\n",
    "df_train, df_temp = train_test_split(df, test_size=0.3, random_state=RANDOM_SEED)\n",
    "df_val, df_test = train_test_split(df_temp, test_size=0.5, random_state=RANDOM_SEED)\n",
    "#save the split data frames to csv just in case\n",
    "df_train.to_csv(CLEAN_DATA_LOCATION+'raw_train.csv', index=False)\n",
    "df_val.to_csv(CLEAN_DATA_LOCATION+'raw_val.csv', index=False)\n",
    "df_test.to_csv(CLEAN_DATA_LOCATION+'raw_test.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T13:02:28.449994Z",
     "start_time": "2024-02-22T13:02:27.859712Z"
    }
   },
   "id": "5b179ec9ca0d9f10"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have a closer look at the training set to see if the data is balanced. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dcaaad7bbb33cdaf"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible sentiments are [list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])\n",
      " list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n",
      " ...\n",
      " list([1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " list([1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      " list([1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])] of 1700 sentiments\n",
      "The number of posts for training is 147857\n"
     ]
    }
   ],
   "source": [
    "print(\"Possible sentiments are\", np.unique(df_train['target']), \"of\", len(np.unique(df_train['target'])),\"sentiments\")\n",
    "print(\"The number of posts for training is\", len(df_train))\n",
    "# size = len(corpus_train) + len(corpus_val) + len(corpus_test)\n",
    "# print(\"Training corpus is \" + str(int(100*np.sum(target_train)/len(target_train))) + \"% positive reviews\")\n",
    "# info = pd.DataFrame([corpus_train[5]], columns=[\"raw text example\"]) #use to track progress\n",
    "# info"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T13:05:13.310854Z",
     "start_time": "2024-02-22T13:05:12.818246Z"
    }
   },
   "id": "5aa4c52b3a69c8e4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f7e93c07f08f7e3"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a66f1a5ed9f18113"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "bafebd9df60dc430"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
